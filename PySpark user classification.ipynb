{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySpark:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack Exchange provides an anonymized [data dump](https://archive.org/details/stackexchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['figure.dpi'] = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bad XML:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local[*]\", \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "def localpath(path):\n",
    "    return 'file://' + os.path.join(os.path.abspath(os.path.curdir), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile(localpath('spark-stats-data/allPosts/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212990"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relationship between reputation and how long it took each person to ask their first question:\n",
    "the difference between (`CreationDate` for the User) and when they asked their first question (`CreationDate` for their first question)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_list=pd.read_csv(\"./q4_solution3/part-00000.csv\")[:100]\n",
    "q4_list['diff']=q4_list['diff'].astype(int)\n",
    "q4_list=q4_list.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "veterans:\n",
    "were active in a time window between 100 and 150 days after account creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local[*]\", \"temp\")\n",
    "sqlContext = SQLContext(sc)\n",
    "import os, time\n",
    "def localpath(path):\n",
    "    return 'file://' + os.path.join(os.path.abspath(os.path.curdir), path)\n",
    "import re\n",
    "#regex = re.compile('\\s*\\<row\\s+(\\w+)=\\\"(.*?)\\\".*(\\w+)=\\\"(\\d+)\\\"')\n",
    "#if re.match('\\s*<row\\s*(\\w+=\".*?\"\\s*)*/>',line):\n",
    "valid_stack_posts_lines=sc.textFile(localpath(\"spark-stack-data/allPosts/\"))\\\n",
    ".filter(lambda x: (\" />\" in x)&(\"  <row\" in x)&(' CreationDate=\\\"' in x))\n",
    "#.filter(lambda x: regex.match(x))\n",
    "valid_stack_users_lines = sc.textFile(localpath(\"spark-stack-data/allUsers/\"))\\\n",
    ".filter(lambda x: (\" />\" in x)&(\"  <row\" in x)&(' CreationDate=\\\"' in x)&(' Id=\\\"' in x))\n",
    "#.filter(lambda x: regex.match(x))\n",
    "#part1\n",
    "\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "day=24*60*60\n",
    "def successMatches2(s):\n",
    "    IdReg= re.search(' Id=\\\"(\\d+)\\\" ',s)\n",
    "    CreationDateReg=re.search(' CreationDate=\\\"(.*?)\\\" ',s)\n",
    "    if IdReg:\n",
    "        Id=int(IdReg.group(1))\n",
    "    else:\n",
    "        Id=0\n",
    "    if CreationDateReg:\n",
    "        CreationDate= CreationDateReg.group(1)\n",
    "        time_stamp=time.mktime(datetime.datetime.strptime(CreationDate, \"%Y-%m-%dT%H:%M:%S.%f\").timetuple())\n",
    "    else:\n",
    "        time_stamp=None\n",
    "    return Id,time_stamp/day\n",
    "\n",
    "#successMatches2(valid_stack_posts_lines.take(1)[0])\n",
    "\n",
    "#q6 dates to df\n",
    "q6_creationdate=valid_stack_users_lines.map(lambda x: successMatches2(x))#.map(lambda line: (line[0],line[1]))\n",
    "#cols2= Array(\"Id\", \"cdate\");\n",
    "df_q6_cdate= q6_creationdate.toDF().selectExpr(\"_1 as Id\", \"_2 as cdate\")\n",
    "\n",
    "#part2\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "#time.mktime(datetime.datetime.strptime(s, \"%d/%m/%Y\").timetuple())\n",
    "#dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS\") \n",
    "def successMatches1(s):\n",
    "\n",
    "    OwnerUserIdReg= re.search(' OwnerUserId=\\\"(\\d+)\\\" ',s)\n",
    "    CreationDateReg=re.search(' CreationDate=\\\"(.*?)\\\" ',s)\n",
    "    AnswerCountReg= re.search(' AnswerCount=\\\"(\\d+)\\\" ',s)\n",
    "    ViewCountReg= re.search(' ViewCount=\\\"(\\d+)\\\" ',s)\n",
    "    FavoriteCountReg=re.search(' FavoriteCount=\\\"(.*?)\\\" ',s)\n",
    "    ScoreReg=re.search(' Score=\\\"(.*?)\\\" ',s)\n",
    "    if OwnerUserIdReg:\n",
    "        OwnerUserId=int(OwnerUserIdReg.group(1))\n",
    "    else:\n",
    "        OwnerUserId=0\n",
    "    if FavoriteCountReg:\n",
    "        FavoriteCount= int(FavoriteCountReg.group(1))\n",
    "    else:\n",
    "        FavoriteCount=0\n",
    "    if AnswerCountReg:\n",
    "        AnswerCount=int(AnswerCountReg.group(1))\n",
    "    else:\n",
    "        AnswerCount=0\n",
    "    if ViewCountReg:\n",
    "        ViewCount= int(ViewCountReg.group(1))\n",
    "    else:\n",
    "        ViewCount=0\n",
    "    if ScoreReg:\n",
    "        Score=int(ScoreReg.group(1))\n",
    "    else:\n",
    "        Score=0\n",
    "    if CreationDateReg:\n",
    "        CreationDate= CreationDateReg.group(1)\n",
    "        time_stamp=time.mktime(datetime.datetime.strptime(CreationDate, \"%Y-%m-%dT%H:%M:%S.%f\").timetuple())\n",
    "    else:\n",
    "        time_stamp=0\n",
    "    \n",
    "    return OwnerUserId,time_stamp/day,Score,FavoriteCount,ViewCount,AnswerCount\n",
    "valid_stack_posts_lines_questions = valid_stack_posts_lines\\\n",
    ".filter(lambda x: (' PostTypeId=\\\"1\\\"' in x)&(' OwnerUserId=\\\"' in x))\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "q6_first_qs=valid_stack_posts_lines_questions.map(lambda x: successMatches1(x))\\\n",
    ".map(lambda line: (line[0],(line[1],line[2],line[3],line[4],line[5])))\\\n",
    ".reduceByKey(lambda L, R: (L[0],L[1],L[2],L[3],L[4]) if (L[0] < R[0]) else (R[0],R[1],R[2],R[3],R[4]))\\\n",
    ".map(lambda line: (line[0],line[1][0],line[1][1],line[1][2],line[1][3],line[1][4]))\n",
    "df_q6_user_info= q6_first_qs.toDF().selectExpr(\"_1 as Id\", \"_2 as cdate\",\"_3 as Score\",\"_4 as FavoriteCount\",\"_5 as ViewCount\",\"_6 as AnswerCount\")\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start) \n",
    "\n",
    "df_q6_user_info.filter(df_q6_user_info.Id==29).show()\n",
    "\n",
    "#part3\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from pyspark.sql.functions import min\n",
    "from pyspark.sql.types import IntegerType\n",
    "#time.mktime(datetime.datetime.strptime(s, \"%d/%m/%Y\").timetuple())\n",
    "#dateFormat = new SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSS\") \n",
    "def successMatches3(s):\n",
    "\n",
    "    OwnerUserIdReg= re.search(' OwnerUserId=\\\"(\\d+)\\\" ',s)\n",
    "    CreationDateReg=re.search(' CreationDate=\\\"(.*?)\\\" ',s)\n",
    "    if OwnerUserIdReg:\n",
    "        OwnerUserId=int(OwnerUserIdReg.group(1))\n",
    "    else:\n",
    "        OwnerUserId=0\n",
    "    if CreationDateReg:\n",
    "        CreationDate= CreationDateReg.group(1)\n",
    "        time_stamp=time.mktime(datetime.datetime.strptime(CreationDate, \"%Y-%m-%dT%H:%M:%S.%f\").timetuple())\n",
    "    else:\n",
    "        time_stamp=0    \n",
    "    return OwnerUserId,time_stamp/day\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "q6_postdate=valid_stack_posts_lines\\\n",
    ".filter(lambda x: (' OwnerUserId=\\\"' in x)).map(lambda x: successMatches3(x))\n",
    "\n",
    "df_q6_pc=q6_postdate.toDF().selectExpr(\"_1 as Id\", \"_2 as pcdate\")\n",
    "\n",
    "#people.filter(people.age > 30).join(department, people.deptId == department.id) \\\n",
    "#  .groupBy(department.name, \"gender\").agg({\"salary\": \"avg\", \"age\": \"max\"})\n",
    "\n",
    "#q6_vet_joined=df_q6_pc.join(df_q6_cdate, df_q6_pc.Id == df_q6_cdate.Id)\n",
    "q6_vet_joined=df_q6_pc.join(df_q6_cdate, [\"Id\"])\n",
    "\n",
    "df_q6_users=q6_vet_joined.withColumn(\"diff\", q6_vet_joined.pcdate -q6_vet_joined.cdate).na.drop()\n",
    "df_q6_users=df_q6_users.filter((df_q6_users.diff > 100) & (df_q6_users.diff < 150))\n",
    "\n",
    "#df_q6_vets=df_q6_users.groupBy(df_q6_users.Id).agg({\"diff\": \"min\"})\n",
    "df_q6_vets=df_q6_users.groupBy(df_q6_users.Id).agg(min(df_q6_users.diff/100)\\\n",
    ".cast(IntegerType()).alias(\"vet\"))\n",
    "\n",
    "q6_info=df_q6_user_info.join(df_q6_vets,on=[\"Id\"], how='left_outer').na.fill(0)\n",
    "\n",
    "#Your statements here\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start) \n",
    "\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "q6_info.rdd.map(lambda x: (x[6],(x[2],x[3],x[4],x[5],1)))\\\n",
    ".reduceByKey(lambda L, R: (L[0]+R[0],L[1]+R[1],L[2]+R[2],L[3]+R[3],L[4]+R[4]))\\\n",
    ".mapValues(lambda x: (x[0]/x[4],x[1]/x[4],x[2]/x[4],x[3]/x[4],x[4]))\\\n",
    ".map(lambda line: (line[0],line[1][0],line[1][1],line[1][2],line[1][3],line[1][4])).collect()\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
