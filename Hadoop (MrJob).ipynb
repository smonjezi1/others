{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapReduce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['figure.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python my_job.py -r local ./part-00026.xml.bz2 > /tmp/output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top100 words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python my_job.py -r local ./data/part-0000*.xml.bz2 > ./tmp/output.txt\n",
    "python my_job.py -r local ./data/part-000*.xml.bz2 > ./tmp/output.txt | More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2520"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "directory =os.path.join(\"./MrJob/tmp\") \n",
    "f=open(os.path.join(directory, 'output.txt'),'r')\n",
    "d={}\n",
    "s=0\n",
    "for line in f.readlines():\n",
    "    line=line.rstrip('\"\\n')\n",
    "    d[line.split('\\t\"',1)[1]]=int(line.split('\\t\"',1)[0])\n",
    "words_sorted = sorted(d.items(), key=lambda kv: kv[1], reverse=True)\n",
    "len(words_sorted)  \n",
    "#words_sorted[0:100]\n",
    "#    for i in re.split('\\t',line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1871079"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "directory =os.path.join(\"./MrJob/tmp\")\n",
    "d={}\n",
    "s=0\n",
    "for i in range(27):\n",
    "    f=open(os.path.join(directory, 'output'+str(\"{0:0=2d}\".format(i))+'.txt'),'r')\n",
    "    for line in f.readlines():\n",
    "        line=line.rstrip('\"\\n')\n",
    "        if line.split('\\t\"',1)[1] in d.keys():\n",
    "            d[line.split('\\t\"',1)[1]]=d[line.split('\\t\"',1)[1]]+int(line.split('\\t\"',1)[0])\n",
    "        else:\n",
    "            d[line.split('\\t\"',1)[1]]=int(line.split('\\t\"',1)[0])\n",
    "words_sorted = sorted(d.items(), key=lambda kv: kv[1], reverse=True)\n",
    "len(words_sorted)  \n",
    "#words_sorted[0:100]\n",
    "#    for i in re.split('\\t',line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'one' in d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sas', 'asas', 'asas', 'the', 'sasa112', '1212', 'the', 'sasa', 'a', 'asa']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.compile(r\"\\w+\").findall('sas asas asas) the . sasa112 1212  the sasa a asa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top100 words simple text:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid or missing encoding declaration for './MrJob/data/part-00000.xml.bz2' (<string>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid or missing encoding declaration for './MrJob/data/part-00000.xml.bz2'\n"
     ]
    }
   ],
   "source": [
    "import lxml.etree\n",
    "root = etree.parse(r'./MrJob/data/part-00000.xml.bz2')\n",
    "et = lxml.etree.fromstring('''<item><img src=\"cat.jpg\" /> Picture of a cat</item>''')\n",
    "et.find('img').tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python q2_4.py -r local ./data/text_all.txt  > ./tmp/output2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "931584"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "directory =os.path.join(\"./MrJob/tmp\")\n",
    "d={}\n",
    "s=0\n",
    "for i in range(1):\n",
    "    f=open(os.path.join(directory, 'output'+str(2)+'.txt'),'r')\n",
    "    for line in f.readlines():\n",
    "        line=line.lstrip('\"').rstrip('\\n')\n",
    "        line=line.split('\"\\t')\n",
    "        if line[0] in d.keys():\n",
    "            d[line[0]]=d[line[0]]+int(line[1])\n",
    "        else:\n",
    "            d[line[0]]=int(line[1])\n",
    "words_sorted = sorted(d.items(), key=lambda kv: kv[1], reverse=True)\n",
    "len(words_sorted)\n",
    "#words_sorted[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mwparserfromhell\n",
    "from mwparserfromhell import parser\n",
    "value=\"{{jjb}}{{g}}\"\n",
    "wikicode = mwparserfromhell.parse(value)\n",
    "bigString = wikicode.strip_code()\n",
    "bigString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top100 words simple no metadata:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n', 3535544),\n",
       " ('the', 1382504),\n",
       " ('of', 746958),\n",
       " ('in', 567163),\n",
       " ('and', 547192),\n",
       " ('a', 507283),\n",
       " ('to', 416224),\n",
       " ('is', 390754),\n",
       " ('ncategory', 265771),\n",
       " ('was', 209422),\n",
       " ('xe2', 202801),\n",
       " ('it', 201328),\n",
       " ('x80', 200970),\n",
       " ('for', 183357),\n",
       " ('0', 159950),\n",
       " ('on', 159391),\n",
       " ('that', 154241),\n",
       " ('as', 146911),\n",
       " ('s', 142411),\n",
       " ('align', 141125),\n",
       " ('xc3', 136109),\n",
       " ('by', 131593),\n",
       " ('are', 128969),\n",
       " ('from', 125740),\n",
       " ('1', 125434),\n",
       " ('2', 124002),\n",
       " ('with', 120777),\n",
       " ('he', 118543),\n",
       " ('this', 102596),\n",
       " ('be', 101229),\n",
       " ('i', 96700),\n",
       " ('or', 94969),\n",
       " ('at', 93111),\n",
       " ('an', 92607),\n",
       " ('center', 91638),\n",
       " ('x93', 87082),\n",
       " ('not', 86622),\n",
       " ('people', 78466),\n",
       " ('style', 76501),\n",
       " ('3', 75881),\n",
       " ('other', 75720),\n",
       " ('they', 74332),\n",
       " ('his', 72038),\n",
       " ('xd0', 70341),\n",
       " ('t', 67522),\n",
       " ('have', 66919),\n",
       " ('utc', 65754),\n",
       " ('has', 63386),\n",
       " ('also', 60330),\n",
       " ('american', 59394),\n",
       " ('bgcolor', 59167),\n",
       " ('one', 58041),\n",
       " ('4', 57329),\n",
       " ('right', 56780),\n",
       " ('talk', 56350),\n",
       " ('which', 54441),\n",
       " ('can', 54062),\n",
       " ('but', 53270),\n",
       " ('nthe', 53081),\n",
       " ('were', 52478),\n",
       " ('new', 50562),\n",
       " ('first', 50557),\n",
       " ('5', 50506),\n",
       " ('there', 46139),\n",
       " ('you', 45253),\n",
       " ('references', 44553),\n",
       " ('rowspan', 43670),\n",
       " ('left', 43099),\n",
       " ('b', 42678),\n",
       " ('6', 42075),\n",
       " ('about', 41451),\n",
       " ('redirect', 41115),\n",
       " ('d', 40078),\n",
       " ('may', 39357),\n",
       " ('all', 38666),\n",
       " ('who', 38164),\n",
       " ('their', 37973),\n",
       " ('if', 37406),\n",
       " ('used', 36523),\n",
       " ('when', 36088),\n",
       " ('had', 35929),\n",
       " ('more', 35431),\n",
       " ('city', 35425),\n",
       " ('10', 35288),\n",
       " ('2009', 35215),\n",
       " ('made', 34715),\n",
       " ('united', 34516),\n",
       " ('time', 34293),\n",
       " ('7', 34193),\n",
       " ('many', 33964),\n",
       " ('she', 33637),\n",
       " ('background', 33500),\n",
       " ('after', 33427),\n",
       " ('some', 32987),\n",
       " ('2008', 31956),\n",
       " ('two', 31660),\n",
       " ('world', 31549),\n",
       " ('no', 31264),\n",
       " ('called', 31168),\n",
       " ('its', 31005)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "directory =os.path.join(\"./MrJob/tmp\")\n",
    "d={}\n",
    "s=0\n",
    "for i in range(1):\n",
    "    f=open(os.path.join(directory, 'output'+str(3)+'.txt'),'r')\n",
    "    for line in f.readlines():\n",
    "        line=line.lstrip('\"').rstrip('\\n')\n",
    "        line=line.split('\"\\t')\n",
    "        if line[0] in d.keys():\n",
    "            d[line[0]]=d[line[0]]+int(line[1])\n",
    "        else:\n",
    "            d[line[0]]=int(line[1])\n",
    "words_sorted = sorted(d.items(), key=lambda kv: kv[1], reverse=True)\n",
    "len(words_sorted)\n",
    "\n",
    "words_sorted[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(path):\n",
    "   parsedfile = path.replace('.xml', '.txt')\n",
    "   cnone = 0\n",
    "   textlist = []\n",
    "   with open(parsedfile, 'w',encoding='utf-8') as parsed:\n",
    "       with open(path) as xml_file:\n",
    "           root = etree.fromstring(xml_file.read())\n",
    "           nodelist = root.findall('.//text')\n",
    "           for node in nodelist:\n",
    "               textlist.append(node.text)\n",
    "\n",
    "           for text in textlist:\n",
    "               if text:\n",
    "                   parsed.write(cleanup(text)+' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xe0\\xa4\\xaa\\xe0\\xa5\\x8d\\xe0\\xa4\\xb0\\xe0\\xa4\\xbf\\xe0\\xa4\\xa5\\xe0\\xa4\\xbf\\xe0\\xa4\\xac\\xe0\\xa5\\x80'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a='प्रिथिबी'\n",
    "a.encode('utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
